{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swinging for the Fences: Decision Trees in Baseball Analysis\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Baseball, often referred to as \"America's Pastime,\" is a game rich in history, tradition, and statistics. Every play on the field is meticulously recorded, creating a vast pool of data over the years. The systematic analysis of this data can unveil fascinating insights about the game, players, and teams. In recent years, the baseball analytics movement has revolutionized the way teams are constructed and games are played.\n",
    "\n",
    "In this notebook, we delve into an exciting aspect of machine learning—Decision Trees—to analyze baseball statistics. Our goal is to understand how players' performance metrics relate to some of the recognitions in the baseball world. We're particularly interested in exploring whether we can predict a player's likelihood of being an All-Star or MVP based on their statistics.\n",
    "\n",
    "We'll take the following steps to build, visualize, and evaluate our Decision Tree model:\n",
    "1. **Data Preprocessing:** Preparing our data for analysis.\n",
    "2. **Splitting the Data:** Dividing the data into training and testing sets.\n",
    "3. **Training the Decision Tree Model:** Building the Decision Tree model using `sklearn`.\n",
    "4. **Visualizing the Decision Tree:** Understanding the decision-making process of the model.\n",
    "5. **Evaluating Our Model:** Assessing the model's performance.\n",
    "6. **Pruning the Tree:** Implementing regularization to improve the model's generalizability.\n",
    "7. **Behind the Curtain:** A closer look at the math and code coalescence.\n",
    "8. **Conclusion:** Reflecting on the Decision Trees' efficacy in baseball analysis.\n",
    "\n",
    "In addition to the steps mentioned, we'll also ponder on the real-world implications and limitations of applying Decision Trees in baseball analytics.\n",
    "\n",
    "Let's step up to the plate and begin our analysis!\n",
    "\n",
    "---\n",
    "\n",
    "**Repository:** The complete code and dataset used in this analysis are available on GitHub: [medium.com_DecisionTreesBaseball Repository](https://github.com/cardavid11/medium.com_DecisionTreesBaseball). Feel free to explore, clone, or contribute to the repository to enhance this project further.\n",
    "\n",
    "**Disclaimer:** This analysis is for educational purposes only. Baseball outcomes are influenced by numerous factors, and the simplifications made in this analysis do not capture the full complexity of baseball games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Necessary Libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "data = pd.read_csv('generated_baseball_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "# In this part, categorical variables are converted to a numerical format using one-hot encoding, \n",
    "# and any rows with missing values are dropped.\n",
    "data = pd.get_dummies(data, drop_first=True)\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the Data\n",
    "# The data is split into features (X) and target variable (y). It's further split into training and \n",
    "# testing sets to evaluate the model later.\n",
    "X = data.drop('MVP', axis=1)\n",
    "y = data['MVP']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the Decision Tree Model\n",
    "# A Decision Tree classifier is initialized and trained on the training data.\n",
    "clf = DecisionTreeClassifier(max_depth=5)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Decision Tree\n",
    "# The trained Decision Tree is visualized to understand its decision-making process.\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf, filled=True, feature_names=X.columns, class_names=['Not MVP', 'MVP'], rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model\n",
    "# The model is evaluated on the test set using accuracy as the metric.\n",
    "y_pred = clf.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pruning the Tree\n",
    "# A pruned Decision Tree is trained with specific parameters to avoid overfitting.\n",
    "clf_pruned = DecisionTreeClassifier(max_depth=3, min_samples_leaf=10, min_samples_split=20)\n",
    "clf_pruned.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the Pruned Tree\n",
    "#The pruned Decision Tree is visualized to compare its structure with the initial tree.\n",
    "plt.figure(figsize=(20,10))\n",
    "plot_tree(clf_pruned, filled=True, feature_names=X.columns, class_names=['Not MVP', 'MVP'], rounded=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Decision Trees in Baseball?\n",
    "\n",
    "Decision Trees bring a blend of simplicity, interpretability, and effectiveness to the analytical forefront. In baseball, where decisions often need to be made swiftly and with clarity, having a model that mirrors such decision-making processes can be incredibly valuable. The visual nature of Decision Trees makes them intuitive and accessible, not just to data scientists, but potentially to coaches, players, and analysts.\n",
    "\n",
    "Moreover, Decision Trees form the foundation for more complex models like Random Forests and Gradient Boosting Machines (GBM), which can capture even more complex relationships in the data while still retaining a level of interpretability. While they may have their limitations in terms of predictive accuracy compared to some other models, their advantages in terms of understandability and ease of implementation make them a worthwhile consideration in the realm of baseball analytics.\n",
    "\n",
    "As we've seen in this tutorial, with a dataset in hand and a few lines of Python code, one can create a basic yet insightful Decision Tree model to glean meaningful information from baseball statistics. This paves the way for further exploration into more complex models and other machine learning techniques in the quest to uncover new insights in baseball analytics.\n",
    "\n",
    "## Disclaimer:\n",
    "\n",
    "This article is intended for educational purposes only. Baseball, like many sports, has a level of unpredictability and is influenced by numerous factors beyond past statistics and measurable attributes. The analyses and models discussed here are simplistic and do not account for many of the nuanced factors that contribute to baseball outcomes. They are not intended to provide any form of conclusive insights or advise on baseball strategies, player selections, or game outcomes.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
